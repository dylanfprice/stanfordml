X analyze memory usage and figure out where we need to cut
X improve tokenization (e.g. one improvement: we shouldn't split up on apostrophes)
X apply stopwords filtering
X explore using clojure.core.matrix and sparse matrices
X finish documentation in analyze-data.core and make sure it works
X investigate using java.util.zip to read and write compressed data files
  boot.user=> (with-open [out (io/writer (GZIPOutputStream. (io/output-stream "test.txt.gz")))]
         #_=>     (.write out "hello"))
X do we need to keep around the inverse document frequencies? can we just do cosine-similarity between a normal term-frequency vector and tf-idf vectors?
  yes we need to keep around or the magnitudes of the features will be different which will change the direction of the vector!
X refactor tf-idf-document to take a terms-document instead of tf-document
X implement k-nn algorithm
    cosine-similarity(x, y): 1 - dot(x, y) / (norm(x) * norm(y))
    dot-product(x, y): sum(x_1 * y_1, x_2 * y_2, ...)
X see how many dimensions data has
  data with just words has ~ 19000 dimensionts
X reduce memory footprint of read-tf-idf-data
X write tests for find-knn
X be consistent with order of all-terms, idf, item-names in function params and files, maps, etc.t 
- figure out what's broken right now
- write code to measure performance given labelled test data
- refactor functions with options to use destructuring syntax in arg list
- consider changing uses of rest to next?
- write tests for io functions
- make a split for unit/integration tests?
- investigate performance of algorithm
    - does a high cosine similarity correspond to a good prediction?
        no: then trs and sp pages are not very related
        yes: then investigate ways to improve cosine similarity
    - possible changes, create metrics to decide which one:
        - when cosine similarities are very small,
          query and source do not have many matching features
            - if query and source have more 2 or 3 word phrases in common,
              include more n-grams in feature vectors
            - if query and source do not have very many words or phrases in common,
              add more text to source data (e.g. concat route pages on)
            - if query and source use different words that mean the same thing,
              apply PCA to reduce dimensions
      
- vectorz or other implementation: serializing sparse arrays/matrix to a file?
  java Serializable - ObjectOutputStream
- testing
    - testing clojure functions with side-effects
        - DI and protocols for interactions with external services
        - StringReader and StringWriter for IO
        - with-redefs can reach in and redefine Vars
        - there are also mock libraries
    - testing philosophies in clojure, unit vs integration, whether to fully isolate functions
        - one idiom: put both unit and integration together but mark integration with ^:integration or similar
          leiningen knows how to run tests based on these but boot may not
    - equivalent of StringIO
      java.io.StringWriter and java.io.StringReader
